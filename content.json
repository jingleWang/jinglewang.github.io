{"pages":[],"posts":[{"title":"ArrayList源码阅读","text":"ArrayList是List接口的一个可伸缩数组实现，实现了所有List接口的方法，用来存储一组数据，允许所有类型的对象，包括NULL，它是非线程安全的。ArrayList底层是一个可以伸缩的数组，List中的每个元素依次存放在这个数组中，并使用成员变量size来标记List中元素的个数，当插入新元素时，新元素会被放入到数组中size的位置，并将size+1，当删除一个元素时，例如删除下标为n的元素，则将n+1之后的元素向前移动一位，并将size-1。数组是可伸缩的，每次插入时,会检查当前数组是否可以容纳新元素，如果不能则会对其扩容，将数组长度变为原来的1.5倍。除了被动的改变数组长度，ArrayList也提供了2个主动改变数组的方法： 12public void trimToSize()public void ensureCapacity(int minCapacity) trimToSize用于将数组大小缩短为size，减少数组所占用的空间，ensureCapacity用来增加数组长度，以确保数组长度大于minCapacity。 size、isEmpty、get、set、iterator因为是对数组直接操作，所以时间复杂度是O（1）的。 ArrayList平凡的扩容可能会影响插入的性能，所以为了减少ArrayList扩容的次数，可以在初始化阶段，提前指定一个初始化容量。 ArrayList的迭代也是遵循fail-fast机制的，当在迭代过程中，发生结构修改时，会抛出ConcurrentModificationException异常，这个检查是通过modCount实现的。 构造方法1234567891011121314151617181920212223242526public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;} public ArrayList(int initialCapacity) { if (initialCapacity &gt; 0) { this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); }}public ArrayList(Collection&lt;? extends E&gt; c) { elementData = c.toArray(); if ((size = elementData.length) != 0) { // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; }} ArrayList提供了3个构造方法，默认的无参构造函数只是将数组大小赋值为一个空数组，在之后的插入过程中在进行扩容操作，ArrayList(int initialCapacity)方法指定了一个初始化容量大小，构造方法通过指定这个初始化容量新建一个指定大小的数组，当ArrayList元素较多时，可以使用这个构造方法，并传入一个较大的initialCapacity。 add12345public boolean add(E e) { ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;} ArrayList的插入操作一共有2步操作，第一步就是判断当前数组大小是否足够容纳新元素的插入，如果大小不够，则进行扩容，这一步在ensureCapacityInternal中进行，此外在这个方法中，还会对modCount进行自增操作，第二步就可以将新元素放到数组对应的位置了。 扩容当ArrayList中数组长度不够或者调用ensureCapacity方法时，会触发扩容，ArrayList的扩容逻辑非常的简单： 12345678910111213private void grow(int minCapacity) { // overflow-conscious code int oldCapacity = elementData.length; //新数组长度为原来的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //如果新的长度小于指定值，则使用minCapacity if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: //复制 elementData = Arrays.copyOf(elementData, newCapacity); } 默认将会把数组长度扩大为原来的1.5倍。然后从老数组中将所有数据复制到新数组中，替换老数组。 removeArrayList提供了2个remove方法： 123456789101112131415161718192021222324252627282930313233 public E remove(int index) { rangeCheck(index); modCount++; E oldValue = elementData(index); //指定下标的元素 int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); //将下标大于index的元素向前移动 //将数组中最后的元素复制为null 防止内存泄漏 elementData[--size] = null; // clear to let GC do its work return oldValue; } public boolean remove(Object o) { if (o == null) { for (int index = 0; index &lt; size; index++) if (elementData[index] == null) { fastRemove(index); return true; } } else { for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) { fastRemove(index); return true; } } return false; } ArrayList提供了2个remove方法，第一个用来移除指定下标的元素，第二个用来移除指定对象。 get没啥好讲，直接从数组拿数据。。。","link":"/2019/04/23/java/ArrayList源码阅读/"},{"title":"Java垃圾回收","text":"在Java的技术体系中的自动内存管理主要解决了2个问题即内存的分配及内存的回收，在这篇文章中，我们主要讨论的是JVM的垃圾回收机制。对于垃圾回收，我们主要需要考虑3个问题： 哪些内存需要被回收 如何回收 什么时候需要被回收 接下来，我将围绕这3个问题，对Java的垃圾回收做一个简单的介绍。 哪些内存需要被回收在进行内存回收之前，我们首先需要知道，哪些对象可以被回收，需要有一定的方法去判断一个对象是否能被回收。 引用计数算法引用计数算法是一个非常古老的算法，实现非常的简单，判定的效率也非常高，他的思路是在对象中添加一个引用计数器，每当有一个地方引用这个对象时，这个计数器就加1，但一个地方的引用失效时，这个计数器就减1，如果这个计数器为0，就代表这个对象没有被引用，可以被回收。 这个算法，在大部分情况下，都是一个非常不错的算法，当时在Java虚拟机中，并没有使用这个算法来管理内存，主要是因为这个算法无法解决互相循环引用的问题，如下面这段代码 1234567A a = new A();B b = new B();a.b = b;b.a = a;a = null;b = null; 当执行完第5、6行代码时，这2个对象已经不可能在被访问，当时由于他们之间存在着互相引用，这两个对象的引用计数器都不为0，所以如果使用引用计数作为判断算法，这个2个对象将不能被垃圾收集器回收。 可达性分析算法在主流商用虚拟机中，都会使用一种叫可达性分析的方法来确定一个对象是否可以被回收，这种方法的主要思路是从一个GC Root作为起始点，开始向下进行搜索，当一个对象与GC Root之间没有引用链相连的话，就说明这个对象不可用。 如上图所示，虽然Obj 6、7、8直接有相互的关联，但Obj 6与GC Root 之间没有直接的引用链进行连接，所以Obj6，Obj7, Obj8将会被判断为无效对象。 一般的，以下几种类型的对象可以被作为GC Root： Java栈（栈帧中的本地变量表）中的引用的对象 方法区中静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI（Native 方法）引用的对象 4种引用类型 强引用： 普通的引用关系，只要一个对象有强引用存在，那么永远不会被回收。 软引用：当内存即将溢出时，垃圾收集器将软引用的对象纳入回收范围进行回收，如果回收后任没有足够内存，才会抛出内存溢出的异常，用SoftReference来实现 弱引用：被弱引用关联的对象只能存活至下一次垃圾回收之前，用WeakReference来实现 虚引用：最弱的一种引用关系，这种关系完全不会对其生存时间构成影响，这种引用的唯一用处就是在一个对象被回收时，收到一个系统通知。用PhantomReference来实现。 最后一次拯救自己的机会一个在可达性分析中被判断需要回收的对象，在被真正回收之前，可能还要经历2次标记，第一次标记将会筛选出需要执行finallize方法的对象（既重写过finilize方法的类的实例），当对象没有覆盖finalize方法，或者已经执行过finalize方法，则会被判断为不需要执行finalize方法。 所有在第一次标记中被判断为需要执行finalize方法的对象，将会被放入一个叫F-Queue的队列中，稍后JVM会触发执行finalize方法，但并不保证会等待finalize方法执行完毕。finalize方法即是最后一次能拯救自己的机会，在finalize方法中可以将对象赋值给某个类变量。那么在稍后GC对F-Queue的第二次小规模标记时，将会把这些对象移除即将回收的集合，经过2次标记，那么这个对象基本上就会被回收了。 那些在finalize方法中存活下来的对象，如果下一次被判断为需要回收，那么将不会被执行finalize方法，直接被回收。 回收方法区在方法区中，主要回收的是2部分对象：废弃常量和无用的类。废弃的常量就是在任何地方都没有被引用的对象，而无用的类的判断比较复杂需要满足3个条件： 该类所有的实例都已经被回收 加载该类的ClassLoader已经被回收 该类的Class对象没有被引用，在任何地方无法通过反射访问该类 当满足上面三个条件后，这个无用的类，就可以被回收了。 如何回收垃圾收集算法标记-清除算法标记-清除，是一种最基本的垃圾收集算法，分为标记和清除两个步骤：首先标记出那些对象可以被回收，然后在标记完成后统一进行回收操作。这种算法的有2个不足的地方： 效率问题：标记和清除的效率都不高 空间问题：会产生大量的内存碎片，导致为大对象分配内存时无法找到足够的内存空间而提前触发垃圾回收 复制算法为了解决标记清除带来的不足，出现了一种复制算法，这种方法的思路是将内存区域分为2块，每次只使用其中的一块，但这一块内存用尽，将会触发一次垃圾回收，将标记存活的对象复制到另一块内存中，然后将这一块内存一次性全部清空，运行高效，也解决了内存碎片的问题，但是，这需要将内存空间缩小为原来的一半作为代价，而且当存在大量对象存活时，就需要进行较多的复制操作，效率将会变得非常低，所以这种算法一半会用在新生代中。 现在的商业JVM一般都采用这种算法作为新生代的回收机制， 新生代的一个特点就是大多数对象会朝生夕死，所以并不需要按照1：1的比例来划分内存空间，而是可以将内存划分为一块较大的eden空间和2块较小的Survivor空间，每次使用eden和其中的一块Survivor，当回收时，将存活的对象复制到另一块Survivor中，最后清理掉Eden和刚才用过的Survivor，Hotspot虚拟机默认的Eden和Survivor的分配比是8：1，所以至少有90%的内存能被使用，只有10%的内存会被浪费。 在某些场景下，我们会遇到Survivor空间不够用的情况，这时，需要依赖其他内存（老年代）进行分配担保，如果在Survivor中没有足够的空间来容纳存活的对象，那么这些对象将会被直接放入老年代。 标记整理算法针对老年代高存活率的特点，出现了标记整理算法，其中标记过程仍然和之前是一样的，但后续的步骤是将所有存活的对象都向一端移动，然后直接清除边界以外的内存。 分代收集算法分代收集本质上是一种整合前几种算法的思想，它将内存分为新生代和老年代，然后根据不同年代的特点采用合适的收集算法。 HotSpot中根节点的枚举在进行可达性分析时，我们需要非常快速的知道在全局性的属性或栈中，哪些地方是引用，可以作为GC Root，然而，这个寻找的范围是非常大的，如果需要逐个检查，那会非常的耗时，而且在枚举GC root时，必须保证一致性，也就是在分析过程中，对象的引用关系不能发生变化，这就必须要在分析过程中暂停所有线程（Stop the world）。 OopMap在目前主流的JVM中使用的都是准确式GC（能够准确的知道一块内存是否为引用），在HotSpot中，使用了一个叫OopMap的结构来达到这个目的，他会记录下栈和寄存器中那些地方为引用，这样在扫描时就能快速的知道那些地方是GC root。 安全点几乎每一个操作，都将会改变OopMap, 所以如果每执行一条操作就修改一次OopMap，将会带来很多额外的开销，所以就有了安全点的概念，每当程序执行到这些安全点时，才会生成OopMap，所以也只有在执行到安全点的时候，才可以进行GC。 安全点的选择是以“是否具有让程序长时间运行的特征”作为选择依据的。比如:方法调用，循环跳转，异常跳转等。 最后一个问题是，如何在需要GC时，让所有线程都中断在安全点上，一般有2种方案： 抢先式中断：在GC发生时，中断所有线程，如果有线程没有在安全点上，则恢复线程，直到它运行到一个安全点。 主动式中断：这种方法需要设置一个用于标记是否需要GC的标志，当每个线程运行到安全点时，将会主动询问是否需要GC,但标记为真时，挂起当前线程。 安全区当一个线程处于Sleep状态，或者Block状态时，没有被分配CPU时间，无法响应系统的中断请求，也就无法到达该线程的安全点，所以就需要用安全区来解决了。既在某个区域内，引用关系不会发生变化，在任意地方开始GC都是安全的。 什么时候回收分配回收策略对象优先在Eden区进行分配大多数情况下，对象会优先被分配进入Eden区，当Eden没有足够的空间来容纳新对象时，JVM会触发一次Minor GC（新生代GC），将Eden+当前Survivor中的对象复制进入另一块Survivor中，如果存活的对象大小超出Survivor区的大小，JVM将会使用分配担保机制，将对象移入老年代中。 大对象直接进入老年代当出现大对象时，往往会导致提前触发垃圾回收，以及在Eden和Survivor之间出现大量的内存复制，所以JVM提供了一个pretenureSizeThreshold参数，让超过这个大小的对象直接在老年代进行分配内存。 长期存活对象进入老年代当对象没经历一次Minor GC时，他的年龄就增加一岁，当年龄增加到一定的程度（默认15岁），该对象就会没放入老年代中。 动态年龄判断如果在Survivor中相同年龄大小的所有对象大小总和大于Survivor空间的一半，年龄大于等于该年龄的对象就可以直接进入老年代中。 空间分配担保在发生Minor GC之前，JVM会首先检查老年代中最大可用连续空间是否大于新生代所有对象之和，如果这个条件成立，那么Minor GC是安全的，如果不成立，那么将会查看HandlePromotionFailure参数是否设置为允许担保失败，如果允许，将会继续检查老年代最大连续可用空间是否大于历次晋升到老年代的对象的大小总和的平均值，如果大于，则将会触发一次Minor GC, 如果小于，或者不允许担保失败，或者Minor GC失败是，将会触发老年的的Full GC。 Minor GC发生在新生代的垃圾回收，非常频繁，回收速度较快 Full GC发生在老年代的垃圾回收，也叫Major GC, 经常会出现伴随至少一次的Minor GC， 速度比Minor GC慢十倍以上。","link":"/2018/04/16/jvm/垃圾回收/"},{"title":"HashMap源码","text":"HashMap是一个基于散列表的Map实现，和HashTable类似，实现了所有的Map方法，但与HashTable不同的是，HashMap允许key和value的值为null，且HashMap是线程不安全的。HashMap不会保证映射的顺序。 HashMap内部会维护一个数组（table），数组中的每一个元素作为一个桶，插入新元素时，会通过key的hashCode 做hash计算，来知道新元素会被分配到哪个桶中，然后将其插入对应的桶。一个桶的结构有时是一个链表，有时是一棵红黑树，这取决于桶中元素的个数。 对于一个Hash表来说，表中的元素最理想的状态是分布均匀的（最好每个桶中只有一个元素），如果太紧，则会影响查询性能，如果太松散，会增加占用的内存空间，所以需要一定的规则来控制table的大小，在HashMap中，有2个初始化参数来影响HashMap的性能，初始容量和负载因子，初始容量是初始化HashMap时table的长度，负载因子控制触发HashMap扩容时的阈值，一般负载因子为0.75。 HashMap元素的迭代是Fail-fast的，如在迭代时，发生结构修改，那么迭代器会抛出ConcurrentModificationException异常。 构造方法123456789101112131415161718192021222324public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);}public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR);}public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted}public HashMap(Map&lt;? extends K, ? extends V&gt; m) { this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);} HashMap提供了四个构造方法，默认的构造方法，将负载因子赋值为0.75，此外，还提供了可以自定义初始化容量和负载因子的构造函数，最后一个构造函数用于复制一个已经存在的Map。 在第一个构造方法中，有一个tableSizeFor方法，用来计算离initialCapacity最近的一个2次幂，详细分析可以看tableSizeFor分析。 Put1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * Associates the specified value with the specified key in this map. * If the map previously contained a mapping for the key, the old * value is replaced. * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or * &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;. * (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map * previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.) */ public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } /** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don't change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //初始化table if ((p = tab[i = (n - 1) &amp; hash]) == null) //如果桶中没有元素那么直接将新元素置为桶的第一个元素。 tab[i] = newNode(hash, key, value, null); else { Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) //桶中第一个元素即为目标位置 e = p; else if (p instanceof TreeNode) //如果当前桶是一棵，红黑树，则忘树中插入新元素 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else { //如果当前桶是一个连表结构的，在连表中寻找是否已经存在key //如果有则替换为新value //如果没有则在尾部添加新元素 for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { //插入至链表尾部 p.next = newNode(hash, key, value, null); //当桶中元素数超过TREEIFY_THRESHOLD时 将连表转化为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); //子类可重新该方法 return oldValue; } } ++modCount; //记录当前HashMap被修改的次数，用于在迭代时判断HashMap是否被修改，保证Fail-fast特性 if (++size &gt; threshold) resize(); //扩容 afterNodeInsertion(evict); //回调方法 子类重写 return null; } static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); } put时，HashMap会重新计算key的hash值，hash()方法通过对原hashCode的高16位和低16位做了异或处理， 减少hash碰撞，详细的分析见hash。 第一次插入时，会调用resize()方法来初始化table，这一步的分析在之后展开，当初始化table完毕后将会进入真正的插入流程。 首先，put方法会通过key的哈希值，计算当前key所在的桶的序号。 1(n - 1) &amp; hash 这时已经知道了这个key应该放到哪个桶中了，这时会遇到三中情况： 桶中还没有元素及table[(n - 1) &amp; hash] == null 桶中是链表结构 桶中是红黑树结构 当桶中还没有元素时，直接将table[(n - 1) &amp; hash]赋值为新元素，如果桶是红黑树结构的，那么就将新元素插入红黑树中，如果是链表结构的，则会将新元素插入至链表的尾部，且此时，会进行一个判断，如果桶中元素个数超过了TREEIFY_THRESHOLD，且table数组长度超过64，则会将这个链表转化为一颗红黑树。 modCount是用来记录当前HashMap被修改结构（改变map中映射个数的修改）的次数，HashMap以此来保证HashMap迭代的Fail-fast机制, 在使用迭代器时，会用这个字段来判断在迭代过程中，HashMap是否有被插入或删除过新值，如果有则会抛出异常。 扩容HashMap中数据均匀的分布是保证HashMap性能的最核心的要求，之前说过，HashMap是有许多的桶构成的，每一个键值对都放在相应的桶中，在查询时需要先找到存放的桶，然后再在桶中寻找对应的key，桶在HashMap中是一数组的形式存在的，所以只需要知道桶的下标即可，这一个步骤的时间复杂度为O(1), 在桶中寻找key，这一部分的时间复杂度为O(n) (链表) 或者 O(logn)(红黑树)。 因此如果桶的数量太少的话，那么势必每个桶中的键值对将会增加，在桶里寻找key的这个过程的性能将会降低，所以，需要增加桶的数量，将原来桶中的键值对，再重新分配到新的桶中，这就是HashMap的扩容。 HashMap的扩容，是通过resize()方法实现的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) { if (oldCap &gt;= MAXIMUM_CAPACITY) { //当table大小已经超过了最大的容量 //将threshold置为最大值 //以后将不再会触发扩容操作 threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) //将table长度乘2 //threshold*2 newThr = oldThr &lt;&lt; 1; // double threshold } else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else { // zero initial threshold signifies using defaults //初始化 //capacity默认为8 //threshold默认为 8 * 0.75 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { //初始化时计算threshold float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({\"rawtypes\",\"unchecked\"}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) { //将原来桶中的映射放入新桶中 for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else { // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do { next = e.next; if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; } HashMap中，table的长度必须为2的n次幂，这是由HashMap的hash算法所决定的，在之前提到过，计算桶的下标的方法是这样的： 1(n - 1) &amp; hash n是table的长度，举个例子，如果table的capacity是4，那么4-1的二进制就是 0011，与hash做&amp;运算，结果也必然是在0-3之间的。 那么为什么一定是2的n次幂呢？ 2的n次方实际就是1后面n个0，2的n次方-1 实际就是n个1； 例如长度为9时候，3&amp;(9-1)=0 2&amp;(9-1)=0 ，都在0上，碰撞了； 例如长度为8时候，3&amp;(8-1)=3 2&amp;(8-1)=2 ，不同位置上，不碰撞； 这样可以减少hash碰撞的概率。 转换红黑树1234567891011121314151617181920final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) { int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) { TreeNode&lt;K,V&gt; hd = null, tl = null; do { TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else { p.prev = tl; tl.next = p; } tl = p; } while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); } } 将链表转换为红黑树的操作使用treeifyBin实现的，构造一颗红黑树的具体实现不做详细分析，在上述代码中，我们可以看到触发这个转换的条件除了桶中的元素必须大于8个之外，还需要满足table的长度大于64，如果不满足，则只是触发扩容操作。 get经过对put的分析，get的实现逻辑已经很清晰了。 12345678910111213141516171819202122232425262728293031public V get(Object key) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; } /** * Implements Map.get and related methods * * @param hash hash for key * @param key the key * @return the node, or null if none */ final Node&lt;K,V&gt; getNode(int hash, Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) { if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; } 首先通过hashCode计算桶下标，在对应桶里面寻找对应的key，如果是链表则遍历，如果是红黑树，那么就以二叉查找数的方法查询。 遍历HashMap提供了三个用于遍历的方法： keySet() values() entrySet() 这三个方法分别返回了一个AbstractSet的子实现类，对于set的遍历，我们需要看一下他们迭代器的实现。 12345678//keySetpublic final Iterator&lt;K&gt; iterator() { return new KeyIterator(); }//ValueSetpublic final Iterator&lt;V&gt; iterator() { return new ValueIterator(); }//EntrySetpublic final Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() { return new EntryIterator(); } 由源码看出，这三个set的迭代器的实现类分别是： KeyIterator ValueIterator EntryIterator 这三个类有一个共同的父类HashIterator 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960abstract class HashIterator { Node&lt;K,V&gt; next; // next entry to return Node&lt;K,V&gt; current; // current entry int expectedModCount; // for fast-fail int index; // current slot HashIterator() { expectedModCount = modCount; Node&lt;K,V&gt;[] t = table; current = next = null; index = 0; if (t != null &amp;&amp; size &gt; 0) { // advance to first entry do {} while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); } } public final boolean hasNext() { return next != null; } final Node&lt;K,V&gt; nextNode() { Node&lt;K,V&gt;[] t; Node&lt;K,V&gt; e = next; if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (e == null) throw new NoSuchElementException(); if ((next = (current = e).next) == null &amp;&amp; (t = table) != null) { do {} while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); } return e; } public final void remove() { Node&lt;K,V&gt; p = current; if (p == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); current = null; K key = p.key; removeNode(hash(key), key, null, false, false); expectedModCount = modCount; } } final class KeyIterator extends HashIterator implements Iterator&lt;K&gt; { public final K next() { return nextNode().key; } } final class ValueIterator extends HashIterator implements Iterator&lt;V&gt; { public final V next() { return nextNode().value; } } final class EntryIterator extends HashIterator implements Iterator&lt;Map.Entry&lt;K,V&gt;&gt; { public final Map.Entry&lt;K,V&gt; next() { return nextNode(); } } 由以上代码可以看出，这三个迭代器的实现类只重写了next方法，分别返回key， value 和 entry，主要的实现都放在了HashIterator中。 在创建一个迭代器时，首先会记录此时的modCount， 之前说过，这个字段是用来判断在迭代过程中HashMap是否被修改的，index是当前所在的桶的序号，然后将迭代器的头个元素指向第一个Node。 在三个重写的next()方法中，都会调用nextNode()方法，这是迭代器的获得下一个元素的实现，他会依次遍历HashMap中的每一个桶，在每次调用时，都会比较当前modCount和之前记录的modCount是否相同，如果不同，则代表HashMap已经发生了结构修改，那么此时就会抛出ConcurrentModificationException异常，这就是HashMap遍历时的Fail-fast机制。","link":"/2019/04/19/java/HashMap/"},{"title":"ConcurrentHashMap源码浅析","text":"基本数据结构 用数组存储每个桶的首节点 使用hash值分桶 hash值相同的元素，以链表的形式存放在桶中 当一个桶内的元素超过8个时，将链表转换为红黑树 Node类123456static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next;} map中最基本的结构，由4个成员变量组成： hash：当前结点的hash值，在子类中，hash值可以为负，有特殊含义 key： 结点的key val：结点的value next：指向下一个结点的指针 此外还提供一个方法find方法12345678910111213141516/** * Virtualized support for map.get(); overridden in subclasses. */Node&lt;K,V&gt; find(int h, Object k) { Node&lt;K,V&gt; e = this; if (k != null) { do { //在链表中寻找 K ek; if (e.hash == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; } while ((e = e.next) != null); } return null;} 当桶中元素以链表形式存储时，调用find函数寻找对应元素，当以红黑树存放时，调用TreeNode中的find函数查找。 TreeBin类当每个桶中元素超过8个时，会将链表变为一颗红黑树，TreeBin是红黑树的包装类，保存了红黑树的根节点，此外这个类提供一个读写锁，用于在红黑树进行调整的时候进行线程，红黑书的基本结点为TreeNode类型 ForwardingNode类型在扩容过程中，当前桶已经完成遍历时，将当前桶在table数组中标记为ForwardingNode类型，当调用get方法查询该桶内元素时，实际调用该类的find方法去nextTable中寻找对应数据。 put方法流程 源码分析1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586/** Implementation for put and putIfAbsent */final V putVal(K key, V value, boolean onlyIfAbsent) { //当key为null时，抛出异常，所有ConcurrentHashMap的key不能为null if (key == null || value == null) throw new NullPointerException(); //计算新节点的hash值 int hash = spread(key.hashCode()); int binCount = 0; //进入一个死循环，当插入成功后才能跳出循环 for (Node&lt;K,V&gt;[] tab = table;;) { Node&lt;K,V&gt; f; int n, i, fh; K fk; V fv; //当前table为空，初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); //对应桶首节点为空，cas插入新的桶节点 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) { if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value))) break; // no lock when adding to empty bin } //对应桶在进行扩容，即该结点类型为`ForwardingNode` else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); //判断首结点 else if (onlyIfAbsent &amp;&amp; fh == hash &amp;&amp; // check first node ((fk = f.key) == key || fk != null &amp;&amp; key.equals(fk)) &amp;&amp; (fv = f.val) != null) return fv; else { V oldVal = null; //进入临界区 synchronized (f) { if (tabAt(tab, i) == f) { //如果以链表形式存放，将新节点插入链接最后位置 if (fh &gt;= 0) { binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) { K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) { pred.next = new Node&lt;K,V&gt;(hash, key, value); break; } } } //如果以红黑树形式存放，将新节点插入红黑树 else if (f instanceof TreeBin) { Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } else if (f instanceof ReservationNode) throw new IllegalStateException(&quot;Recursive update&quot;); } } if (binCount != 0) { //如果桶内元素树达到临界值，转换为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i);、 //如果当前key已存在，则替换对应node中的value，返回，不需要改变计数器 if (oldVal != null) return oldVal; break; } } } addCount(1L, binCount); return null;} 多个线程可以同时调用，在插入时，只对对应桶进行加锁操作，粒度更细 initTable方法initTable可以运行多个线程同时调用，但只有一个线程可以进行初始化，其他线程通过yield让出cpu 流程图 源码分析123456789101112131415161718192021222324252627282930313233343536373839/** * Initializes table, using the size recorded in sizeCtl. * sizeCtl 状态： * 1. = -1 : 正在初始化 * 2. &lt; -1 : 正在扩容，数值为 -(1 + 参与扩容的线程数) * 3. = 0 : 创建时初始为0 * 4. &gt; 0 : 下一次扩容的大小 */private final Node&lt;K,V&gt;[] initTable() { Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) { //其他线程正进行操作，让出cpu if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin /* * 将sizeCtl改为初始化状态，由于使用cas方法，可以保证： * 如果改变状态后，没有其他线程可以进入以下代码段； * 如果该cas方法执行失败，代表其他线程已经进入了该代码段，所以需要重新进入循环获得新的sizeCtl */ else if (U.compareAndSetInt(this, SIZECTL, sc, -1)) { try { //进行初始化操作 //由于所有之前让出cpu的线程最终都会进入该代码块，所以需要在这里重新判断一下table是否为空，如果已经初始化则跳出 if ((tab = table) == null || tab.length == 0) { int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; sc = n - (n &gt;&gt;&gt; 2); } } finally { sizeCtl = sc; } break; } } return tab;} 扩容扩容的触发在每次调用put方法进行数据插入后，都会调用addCount方法进行计数器的更新，当元素数量满足扩容条件后调用transfer进行扩容，多个线程可以进行协助扩容。在扩容过程中，新的数据存放在nextTable中。 扩容的整体思路 首先对nextTable数组进行初始化，该操作只能由一个数组完成。 对整个table数组进行遍历，将table中元素复制到nexttable中： 如果当前位置元素为null，则将该位置的数组元素替换为ForwordingNode节点。 如果当前位置元素为非空，则将桶内元素重新放入正确位置。 如果该桶已经处理完毕，就将该桶的首元素替换为ForwardingNode节点。 当所有节点都完成了扩容，将table赋值为nextTable，sizeCtl复制为新容量的0.75倍 多线程扩容ConcurrentHashMap中存在一个叫transferIndex的成员变量，代表下一个需要进行元素复制的桶的下标，当存在线程对该下标对应的桶进行操作时，将transfer利用cas设置成下个需要操作的桶下标，由于使用了cas和volatile，实现了多线程进行数组遍历，进而实现多线程协同遍历;每当处理完一个节点，将该节点set成forwordingNode,当其他节点处理到这个节点后，直接跳过。 代码分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168/** * Moves and/or copies the nodes in each bin to new table. See * above for explanation. */private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) { int n = tab.length, stride; if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range //当nextTable==null，初始化nextTable if (nextTab == null) { // initiating try { @SuppressWarnings(&quot;unchecked&quot;) //将nextTable初始化为table大小的2倍 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; } catch (Throwable ex) { // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; } nextTable = nextTab; //设置transfetIndex为table最后一个桶 transferIndex = n; } int nextn = nextTab.length; ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab //开始循环遍历（table从后往前） //i为当前进行复制的桶，bound表示当前线程需要复制下标在bound之前的桶 for (int i = 0, bound = 0;;) { Node&lt;K,V&gt; f; int fh; //遍历从nextIndex到transferIndex之间的桶 while (advance) { int nextIndex, nextBound; //当前桶还在bound之间 if (--i &gt;= bound || finishing) advance = false; //当table中所有的桶已经被复制 else if ((nextIndex = transferIndex) &lt;= 0) { i = -1; advance = false; } //当线程首次进入该循环， //或已经完成上次设置范围内桶复制，但还有桶未被复制时 //设置该线程需要复制的桶的下标范围 else if (U.compareAndSetInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) { bound = nextBound; i = nextIndex - 1; advance = false; } } //完成扩容 if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) { int sc; //当finishing标记为ture时，表示整个扩容过程已经完成，进行扫尾工作 if (finishing) { //将table 赋值为 nextTable； 将nextTable赋值为null 重置 sizeCtl nextTable = null; table = nextTab; sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; } //该线程已经完成了扩容任务，在退出前需要检查其他线程是否还在进行扩容 //如果还存在未完成的线程，结束操作 //如果所有线程已经完成扩容，则将finishing标记为true，在进行一次完成扩容的检查。 if (U.compareAndSetInt(this, SIZECTL, sc = sizeCtl, sc - 1)) { //判断其他线程是否还在进行扩容 if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; //所有线程都完成扩容 finishing = advance = true; //由于在退出之前需要再次对所有节点进行一次检查，所有将i再次设置为n，对table再次进行一次遍历 i = n; // recheck before commit } } //如果当前桶中没有元素，修改为forwardingNode else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); //当前桶已经完成扩容，跳过该桶，进入下一个桶 else if ((fh = f.hash) == MOVED) advance = true; // already processed //没有进行过扩容操作，将元素从table中移动到nextTable中 else { synchronized (f) { if (tabAt(tab, i) == f) { Node&lt;K,V&gt; ln, hn; if (fh &gt;= 0) { int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) { int b = p.hash &amp; n; if (b != runBit) { runBit = b; lastRun = p; } } if (runBit == 0) { ln = lastRun; hn = null; } else { hn = lastRun; ln = null; } for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) { int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); } setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; } else if (f instanceof TreeBin) { TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) { int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) { if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; } else { if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; } } ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; } } } } }}","link":"/2018/02/01/java/ConcurrentHashMap源码浅析/"},{"title":"RPC","text":"​ 第一次用到RPC框架是在实习公司的那段时间做一个搜索引擎的项目，使用了阿里的Dubbo，用来打通不同工程间的信息交互，当时对RPC框架并不是非常了解，只知道用它可以将远程服务像本地方法一样得调用，虽然对它有着一点好奇，却也并没有打算去深入了解他。后来，大四准备毕业设计了，也没有什么好的想法，所以就想写一个自己的RPC框架，重复造个轮子，权当学习，本文只是简单的介绍一下RPC框架。 RPC是什么​ 远程过程调用（Remote Procedure Call，缩写为 RPC），顾名思义，就是一个允许在分布式环境中通过网络像调用本地方法一样调用其他远程服务器提供的服务的协议。它假定了某些通信协议的存在，如TCP、UDP、HTTP，并利用这些通信协议进行信息传递，在OSI模型中它跨越了应用层和传输层，所以在使用RPC协议时，并不需要关注底层的通信，这大大简化了分布式系统的开发难度。 ​ RPC采用的是C/S模型，请求程序是一个客户机，服务提供方是一个服务器。 如上图所示，Client发起一个请求，RPC框架将这个请求发送到服务提供方Server，此时Client将会一直等待直到Server处理完毕并返回结果或超时，此时Server接受到Client发送的请求，并对这个请求进行解析，计算结果，将结果以同样的方式返回，然后Server重新进入监听状态，以迎接下一个请求的到来。 ​ 总的来说，RPC框架就是一个不同系统之间进行交互的聊天工具。在开发分布式应用时，完全不需要考虑底层到底是用了HTTP协议，还是其他通信协议，因为这是RPC框架自己的事情，而你只要告诉RPC框架，你需要调用的是什么方法。 RPC存在的意义​ 在DUBBO的USER BOOK中，介绍了四种随着互联网发展，网站应用不断扩大规模是，必定会经历的4中网站架构：单一应用架构、垂直应用架构、分布式服务架构和流动计算架构。 ​ 在起步阶段，网站的流量很小，为减少部署节点和成本，可以将所有的功能放在一个应用中，随着网站的发展，流量慢慢变大，单一应用架构已经不足以支撑日益增加的访问量，此时可以将一个应用拆分成多个互不相干的应用，以提升单个应用的效率，这便是垂直应用架构，随着网站规模进一步的扩大，垂直应用越来越多，应用间的交互不可避免，所以需要将核心的业务从应用中抽离出来，变成公共的服务，而此时，一个能整合业务复用及整合的RPC框架就是关键。当服务越来越多，服务的管理就成了一个问题，这时候灵活的服务治理（SOA)就是最重要的地方。 ​ 无论是什么网站，殊途同归，微服务总是最终的归宿，如何让各个服务之间相互的调用变得简单和高效，这就是一个RPC框架应该去解决的问题， 结构在 Nelson 1984年发表的论文 Implementing Remote Procedure Calls 中提出，RPC由5个部分组成： User User Stub RPCRuntime Server Stub Server 这5个部分的联系如下图所示 根据 Nelson 的描述，当远程调用发生时，User调用的是本地的User Stub，User stub 将请求根据协议打包成一个消息，通过RPCRuntime传递到服务端，此时，客户端将进入等待状态。服务端的RPCRuntime接受客户端的请求消息，接着经由Server Stub拆包，调用本地方法进行相应计算，获得结果。最后将结果经由相同的链路发送到客户端User手中，进行返回。 ​ 传统的RPC模型只描述了点到点的调用流程，在实际运用中，还需要考虑负载均衡、服务的高可用等问题，所以产品级的RPC框架一般还会有一个注册中心来提供服务的发现、注销和负载均衡等功能。 在Client 和 Server 直接还是如 Nelson 的模型一样进行连接，与Nelson 不同的是Client和Server都需要与一个注册中心Register进行通信，当有新的Server发布时，Server 需要向 Register 进行注册， 此时，Register 会通知所有的Client有新的服务发布，并更新Client的缓存，当Client发起远程调用时，会在缓存中选取一台Server进行通信。Client 和 Server 与 Register 都有心跳检测，所以，当集群中某一台服务器下线时，Register 会马上知道，并会通知所有的Client该服务器下线，刷新Client缓存。 流程总结一下在 Nelson 描述的调用模型中，远程服务调用的步骤： client调用client stub，这是一次本地过程调用。 client stub将参数打包成一个消息，然后发送这个消息。 client所在的系统将消息发送给server。 server的的系统将收到的包传给server stub。 server stub解包得到参数。 最后server stub调用服务过程. 返回结果按照相反的步骤传给client。 REFERGo RPC 开发指南 深入浅出 RPC - 浅出篇","link":"/2018/02/05/rpc/RPC/"},{"title":"（二）环境资源管理","text":"spring 中的运行环境通过Environment进行管理。环境分为2种：profile和property。 profile的作用是，在实际开发中，开发环境和实际线上环境的配置是不同的，但是如何能不修改代码就可以让代码在2个不同的环境中运行呢，profile就是用来解决这个问题的，可以为一个bean指定一个或多个profile，当代码运行在不同环境中时，通过配置profile，spring可以知道是否应该加载这个bean，以此来区分开发环境和正式环境的配置。 property 即常用的资源配置，这里不多赘述。 Environment继承自PropertyResolver, PropertyResolver 声明了解析property部分的方法，而Environment本身则在PropertyResolver的基础上，增加了profile部分的方法。 在Spring中，用Environment主要实现在AbstractEnvironment中，在这里，我将主要对这个类进行分析。在此之前，先来看下Environment和PropertyResolver所声明的方法。 PropertyResolver123456789101112131415//property是否存在boolean containsProperty(String key);String getProperty(String key);String getProperty(String key, String defaultValue);&lt;T&gt; T getProperty(String key, Class&lt;T&gt; targetType);&lt;T&gt; T getProperty(String key, Class&lt;T&gt; targetType, T defaultValue);//当不存在property时会抛出异常String getRequiredProperty(String key) throws IllegalStateException;&lt;T&gt; T getRequiredProperty(String key, Class&lt;T&gt; targetType) throws IllegalStateException;//解析字符串中的占位符String resolvePlaceholders(String text);String resolveRequiredPlaceholders(String text) throws IllegalArgumentException; Environment12345678910//获得所有活动的profileString[] getActiveProfiles();//当未指定活动profile时 会使用默认的profileString[] getDefaultProfiles();//传入的profile是否是活动的@Deprecatedboolean acceptsProfiles(String... profiles);boolean acceptsProfiles(Profiles profiles); AbstractEnvironmentAbstractEnvironment是Environment主要的实现类以下简称AE，所有的实体类都会继承这个类。这个类中，使用了代理模式，将property部分的逻辑，交由PropertySourcesPropertyResolver来实现, 而AbstractEnvironment本身则实现了profile部分的逻辑。首先，先分析一下AbstractEnvironment完整的继承关系。 从上图可以看出，AbstractEnvironment并非直接的实现Environment接口，而是继承了ConfigurableEnvironment和ConfigurablePropertyResolver接口。在这连个接口中，提供了一些用于配置的方法，具体如下： ConfigurablePropertyResolver12345678910111213141516171819//获得/设置类型转换器 用于getProperty方法中的类型转换。ConfigurableConversionService getConversionService();void setConversionService(ConfigurableConversionService conversionService);//设置占位符的前后缀 用于处理${...}void setPlaceholderPrefix(String placeholderPrefix);void setPlaceholderSuffix(String placeholderSuffix);//设置占位符中的分隔符， spring默认的是\":\"，当需要默认值时，只需写成${key:defaultVal}即可void setValueSeparator(@Nullable String valueSeparator);//是否不处理嵌套的占位符void setIgnoreUnresolvableNestedPlaceholders(boolean ignoreUnresolvableNestedPlaceholders);//当进行property验证时，必须验证的propertyvoid setRequiredProperties(String... requiredProperties);//验证setRequiredProperties方法设置的property是否存在且合法void validateRequiredProperties() throws MissingRequiredPropertiesException; ConfigurableEnvironment1234567891011121314151617181920//清空set重新添加活动的profilevoid setActiveProfiles(String... profiles);//在原有的基础上增加活动profilevoid addActiveProfile(String profile);//设置默认profilevoid setDefaultProfiles(String... profiles);//获得PropertySources, PropertySource是时间用来存储property的地方MutablePropertySources getPropertySources();//获取系统propertyMap&lt;String, Object&gt; getSystemProperties();//获取系统环境Map&lt;String, Object&gt; getSystemEnvironment();//合并其他Environment的profile 和 Environmentvoid merge(ConfigurableEnvironment parent); 以上就是AbstractEnvironment提供的所有方法，接下来，看一下他们是如何实现的。 首先，先看看AE的成员变量： 1234567891011private final Set&lt;String&gt; activeProfiles = new LinkedHashSet&lt;&gt;(); //活动的profile set//默认profile的set 如果指定则为{&quot;default&quot;}private final Set&lt;String&gt; defaultProfiles = new LinkedHashSet&lt;&gt;(getReservedDefaultProfiles());//一个用于存放的PropertySource的集合private final MutablePropertySources propertySources = new MutablePropertySources();//上面说到的代理的用于实现property部分逻辑的实现类private final ConfigurablePropertyResolver propertyResolver = new PropertySourcesPropertyResolver(this.propertySources); 在这里需要简单提一下MutablePropertySources这个类。它实际上是一个PropertySource的集合，内部维护了一个List&lt;PropertySource&lt;?&gt;&gt;, 它实现PropertySources接口，而PropertySources又是继承自Iterable&lt;PropertySource&lt;?&gt;&gt;的。在上面代码中其实是建了一个空的PropertySource集合。那么PropertySource又是什么东西呢。从名字上看，就是property的源的意思，所有的property都是从这里获取，是用来存放property的地方。 AE只提供了一个无参的构造方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public AbstractEnvironment() { customizePropertySources(this.propertySources);}/** * Customize the set of {@link PropertySource} objects to be searched by this * {@code Environment} during calls to {@link #getProperty(String)} and related * methods. * * &lt;p&gt;Subclasses that override this method are encouraged to add property * sources using {@link MutablePropertySources#addLast(PropertySource)} such that * further subclasses may call {@code super.customizePropertySources()} with * predictable results. For example: * &lt;pre class=\"code\"&gt; * public class Level1Environment extends AbstractEnvironment { * &amp;#064;Override * protected void customizePropertySources(MutablePropertySources propertySources) { * super.customizePropertySources(propertySources); // no-op from base class * propertySources.addLast(new PropertySourceA(...)); * propertySources.addLast(new PropertySourceB(...)); * } * } * * public class Level2Environment extends Level1Environment { * &amp;#064;Override * protected void customizePropertySources(MutablePropertySources propertySources) { * super.customizePropertySources(propertySources); // add all from superclass * propertySources.addLast(new PropertySourceC(...)); * propertySources.addLast(new PropertySourceD(...)); * } * } * &lt;/pre&gt; * In this arrangement, properties will be resolved against sources A, B, C, D in that * order. That is to say that property source \"A\" has precedence over property source * \"D\". If the {@code Level2Environment} subclass wished to give property sources C * and D higher precedence than A and B, it could simply call * {@code super.customizePropertySources} after, rather than before adding its own: * &lt;pre class=\"code\"&gt; * public class Level2Environment extends Level1Environment { * &amp;#064;Override * protected void customizePropertySources(MutablePropertySources propertySources) { * propertySources.addLast(new PropertySourceC(...)); * propertySources.addLast(new PropertySourceD(...)); * super.customizePropertySources(propertySources); // add all from superclass * } * } * &lt;/pre&gt; * The search order is now C, D, A, B as desired. * * &lt;p&gt;Beyond these recommendations, subclasses may use any of the {@code add&amp;#42;}, * {@code remove}, or {@code replace} methods exposed by {@link MutablePropertySources} * in order to create the exact arrangement of property sources desired. * * &lt;p&gt;The base implementation registers no property sources. * * &lt;p&gt;Note that clients of any {@link ConfigurableEnvironment} may further customize * property sources via the {@link #getPropertySources()} accessor, typically within * an {@link org.springframework.context.ApplicationContextInitializer * ApplicationContextInitializer}. For example: * &lt;pre class=\"code\"&gt; * ConfigurableEnvironment env = new StandardEnvironment(); * env.getPropertySources().addLast(new PropertySourceX(...)); * &lt;/pre&gt; * * &lt;h2&gt;A warning about instance variable access&lt;/h2&gt; * Instance variables declared in subclasses and having default initial values should * &lt;em&gt;not&lt;/em&gt; be accessed from within this method. Due to Java object creation * lifecycle constraints, any initial value will not yet be assigned when this * callback is invoked by the {@link #AbstractEnvironment()} constructor, which may * lead to a {@code NullPointerException} or other problems. If you need to access * default values of instance variables, leave this method as a no-op and perform * property source manipulation and instance variable access directly within the * subclass constructor. Note that &lt;em&gt;assigning&lt;/em&gt; values to instance variables is * not problematic; it is only attempting to read default values that must be avoided. * * @see MutablePropertySources * @see PropertySourcesPropertyResolver * @see org.springframework.context.ApplicationContextInitializer */protected void customizePropertySources(MutablePropertySources propertySources) {} 在构造方法中，它将会调用customizePropertySources方法，在AE中，其实并没有对这个方法进行实现。需要在子类中重新这个类。而这个方法的主要目的是让子类在其中添加一些PropertySource, 如StandardEnvironment中是如下实现的。 1234protected void customizePropertySources(MutablePropertySources propertySources) { propertySources.addLast(new MapPropertySource(SYSTEM_PROPERTIES_PROPERTY_SOURCE_NAME, getSystemProperties())); propertySources.addLast(new SystemEnvironmentPropertySource(SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME, getSystemEnvironment()));} 分析完了构造方法，接下来理一理成员方法的实现。同样的分为2个部分，profile和property，profile部分实现了单纯在Environment中和ConfigurableEnvironment中声明的方法。 123456789101112131415161718192021222324public String[] getActiveProfiles() { return StringUtils.toStringArray(doGetActiveProfiles());}/** * Return the set of active profiles as explicitly set through * {@link #setActiveProfiles} or if the current set of active profiles * is empty, check for the presence of the {@value #ACTIVE_PROFILES_PROPERTY_NAME} * property and assign its value to the set of active profiles. * @see #getActiveProfiles() * @see #ACTIVE_PROFILES_PROPERTY_NAME */protected Set&lt;String&gt; doGetActiveProfiles() { synchronized (this.activeProfiles) { if (this.activeProfiles.isEmpty()) { String profiles = getProperty(ACTIVE_PROFILES_PROPERTY_NAME); if (StringUtils.hasText(profiles)) { setActiveProfiles(StringUtils.commaDelimitedListToStringArray( StringUtils.trimAllWhitespace(profiles))); } } return this.activeProfiles; }} getActiveProfiles方法是用来获得活动profile的，活动profile的获取是懒加载的，当第一次需要获得活动profile时，会通过doGetActiveProfiles`方法，从property中进行加载，这个过程通过对activeProfiles进行加锁，保证了线程安全性。 1234567891011121314151617181920212223242526@Overridepublic void setActiveProfiles(String... profiles) { Assert.notNull(profiles, \"Profile array must not be null\"); if (logger.isDebugEnabled()) { logger.debug(\"Activating profiles \" + Arrays.asList(profiles)); } synchronized (this.activeProfiles) { this.activeProfiles.clear(); for (String profile : profiles) { validateProfile(profile); //判断profile是否合法 (不为空， 不以！开头) this.activeProfiles.add(profile); } }}@Overridepublic void addActiveProfile(String profile) { if (logger.isDebugEnabled()) { logger.debug(\"Activating profile '\" + profile + \"'\"); } validateProfile(profile); doGetActiveProfiles(); synchronized (this.activeProfiles) { this.activeProfiles.add(profile); }} 上面这两个方法是用来添加活动的profile的，区别是set方法是会清空原有的activeProfiles，而add方法只是追加，通样这两个方法都是线程安全的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Overridepublic String[] getDefaultProfiles() { return StringUtils.toStringArray(doGetDefaultProfiles());}/** * Return the set of default profiles explicitly set via * {@link #setDefaultProfiles(String...)} or if the current set of default profiles * consists only of {@linkplain #getReservedDefaultProfiles() reserved default * profiles}, then check for the presence of the * {@value #DEFAULT_PROFILES_PROPERTY_NAME} property and assign its value (if any) * to the set of default profiles. * @see #AbstractEnvironment() * @see #getDefaultProfiles() * @see #DEFAULT_PROFILES_PROPERTY_NAME * @see #getReservedDefaultProfiles() */protected Set&lt;String&gt; doGetDefaultProfiles() { synchronized (this.defaultProfiles) { if (this.defaultProfiles.equals(getReservedDefaultProfiles())) { //检查是否配置spring.profiles.default， 如果是则使用配置的profile作为默认profile String profiles = getProperty(DEFAULT_PROFILES_PROPERTY_NAME); if (StringUtils.hasText(profiles)) { setDefaultProfiles(StringUtils.commaDelimitedListToStringArray( StringUtils.trimAllWhitespace(profiles))); } } return this.defaultProfiles; }}/*** Specify the set of profiles to be made active by default if no other profiles* are explicitly made active through {@link #setActiveProfiles}.* &lt;p&gt;Calling this method removes overrides any reserved default profiles* that may have been added during construction of the environment.* @see #AbstractEnvironment()* @see #getReservedDefaultProfiles()*/@Overridepublic void setDefaultProfiles(String... profiles) { Assert.notNull(profiles, \"Profile array must not be null\"); synchronized (this.defaultProfiles) { this.defaultProfiles.clear(); //清除default validateProfile(profile); //验证profile，如果为空或者以!开头则抛出异常IllegalArgumentException this.defaultProfiles.add(profile); } }} getDefaultProfiles 方法和getActiveProfiles方法类似，当用户没有自定义default profile时， 则会返回default作为默认profile。setDefaultProfiles方法也基本和setActiveProfiles类似，不多赘述。 12345678910111213141516171819202122232425262728293031323334@Override@Deprecatedpublic boolean acceptsProfiles(String... profiles) { Assert.notEmpty(profiles, &quot;Must specify at least one profile&quot;); for (String profile : profiles) { if (StringUtils.hasLength(profile) &amp;&amp; profile.charAt(0) == &apos;!&apos;) { if (!isProfileActive(profile.substring(1))) { return true; } } else if (isProfileActive(profile)) { return true; } } return false;}@Overridepublic boolean acceptsProfiles(Profiles profiles) { Assert.notNull(profiles, &quot;Profiles must not be null&quot;); return profiles.matches(this::isProfileActive);}/** * Return whether the given profile is active, or if active profiles are empty * whether the profile should be active by default. * @throws IllegalArgumentException per {@link #validateProfile(String)} */protected boolean isProfileActive(String profile) { validateProfile(profile); Set&lt;String&gt; currentActiveProfiles = doGetActiveProfiles(); return (currentActiveProfiles.contains(profile) || (currentActiveProfiles.isEmpty() &amp;&amp; doGetDefaultProfiles().contains(profile)));} 接下来是2个判断profile是否活跃的方法，前一个方法已经启用，但是2者实现的原理都是一样的，在activeProfiles和defaultProfiles中是否存在那个profile。 最后来看一下merge方法，merge方法用于将一个父环境中注册的propertySource和profile注册到当前环境中。同样这个方法是线程安全的。 12345678910111213141516171819202122232425@Overridepublic void merge(ConfigurableEnvironment parent) { for (PropertySource&lt;?&gt; ps : parent.getPropertySources()) { if (!this.propertySources.contains(ps.getName())) { this.propertySources.addLast(ps); } } String[] parentActiveProfiles = parent.getActiveProfiles(); if (!ObjectUtils.isEmpty(parentActiveProfiles)) { synchronized (this.activeProfiles) { for (String profile : parentActiveProfiles) { this.activeProfiles.add(profile); } } } String[] parentDefaultProfiles = parent.getDefaultProfiles(); if (!ObjectUtils.isEmpty(parentDefaultProfiles)) { synchronized (this.defaultProfiles) { this.defaultProfiles.remove(RESERVED_DEFAULT_PROFILE_NAME); for (String profile : parentDefaultProfiles) { this.defaultProfiles.add(profile); } } }} 以上，profil部分的实现已经全部分析完了，接下来在对property部分的实现进行分析，之前说了AE是将这部分的逻辑代理到了PropertySourcesPropertyResolver这个类中，所以我将直接对这个类进行分析。 对于PropertyResovler的逻辑，主要是放在了AbstractPropertyResolver中，PropertyResolver提供的方法，可以分为这么几类： property的获取 字符串中property占位符的解析替换 其他的set配置方法 所有的set配置方法，字符串解析的方法都在APR中实现，一部分property在APR中实现，但其最核心的获取操作实现在了PropertySourcesPropertyResolver中。 首先还是看一下APR的成员变量。 12345678910111213141516171819@Nullableprivate volatile ConfigurableConversionService conversionService;@Nullableprivate PropertyPlaceholderHelper nonStrictHelper;@Nullableprivate PropertyPlaceholderHelper strictHelper;private boolean ignoreUnresolvableNestedPlaceholders = false;private String placeholderPrefix = SystemPropertyUtils.PLACEHOLDER_PREFIX;private String placeholderSuffix = SystemPropertyUtils.PLACEHOLDER_SUFFIX;@Nullableprivate String valueSeparator = SystemPropertyUtils.VALUE_SEPARATOR;private final Set&lt;String&gt; requiredProperties = new LinkedHashSet&lt;&gt;(); 第一个变量conversionService 是用来作类型转换的，可以将property通过这个服务把类型转换为目标类型； 第二第三个变量都是PropertyPlaceholderHelper类型的，他们是用来解析字符串中的property, 在这里有严格和非严格的资源占位符解析，如果是严格的，当无法找到相应资源时，将会抛出异常，如果是非严格的，则会将那个占位符替换为空字符串， 他们都是懒加载的。 第四个变量ignoreUnresolvableNestedPlaceholders 是一个布尔类型的配置变量，通过设置这个变量，可以选择是否忽略嵌套的无法解析的占位符； 第五第六个变量用来指定占位符的前缀和后缀，比如${...}; 第七个valueSeparator变量用来分隔占位符中，property的key和默认值，如${key:defaultVal}中的:; 最后一个变量是一个set容器，用来存放调用validateRequiredProperties时，必须存在的资源名称。 对于set方法，这里就不多做说明了，着重来看一下getProperty和resolvePlaceholder系列方法。 对于getProperty类方法，都是依赖PropertySourcesPropertyResolver中的getProperty(String key, Class&lt;T&gt; targetValueType, boolean resolveNestedPlaceholders)方法，所以这里只需要分析这个方法即可。 123456789101112131415161718192021222324protected &lt;T&gt; T getProperty(String key, Class&lt;T&gt; targetValueType, boolean resolveNestedPlaceholders) { if (this.propertySources != null) { for (PropertySource&lt;?&gt; propertySource : this.propertySources) { //依次在注册的propertySource总寻找 if (logger.isTraceEnabled()) { logger.trace(\"Searching for key '\" + key + \"' in PropertySource '\" + propertySource.getName() + \"'\"); } Object value = propertySource.getProperty(key); if (value != null) { if (resolveNestedPlaceholders &amp;&amp; value instanceof String) { //解析嵌套placeholder value = resolveNestedPlaceholders((String) value); } logKeyFound(key, propertySource, value); return convertValueIfNecessary(value, targetValueType); //类型转换 } } } if (logger.isTraceEnabled()) { logger.trace(\"Could not find key '\" + key + \"' in any property source\"); } return null;} 他的逻辑其实非常的简单，依次在所有propertySource中寻找这个property，当找到这个property时，会通过resolveNestedPlaceholders这个方法处理value中嵌套的资源占位符，最后，调用convertValueIfNecessary方法通过ConversionService转换为目标类型。 对字符串中资源占位符的解析，是在PropertyPlaceholderHelper 中完成的，来看下这部分的逻辑： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263protected String parseStringValue( String value, PlaceholderResolver placeholderResolver, Set&lt;String&gt; visitedPlaceholders) { StringBuilder result = new StringBuilder(value); int startIndex = value.indexOf(this.placeholderPrefix); //寻找第一个${前缀 while (startIndex != -1) { //存在占位符，则进行处理 int endIndex = findPlaceholderEndIndex(result, startIndex); if (endIndex != -1) { String placeholder = result.substring(startIndex + this.placeholderPrefix.length(), endIndex); //拿出占位符key String originalPlaceholder = placeholder; if (!visitedPlaceholders.add(originalPlaceholder)) { //判断是否存在循环引用的情况 即 placeholder=${placeholder} throw new IllegalArgumentException( \"Circular placeholder reference '\" + originalPlaceholder + \"' in property definitions\"); } // Recursive invocation, parsing placeholders contained in the placeholder key. placeholder = parseStringValue(placeholder, placeholderResolver, visitedPlaceholders); //处理placeholder中嵌套的占位符，获得真正的key 如#{#{key}} // Now obtain the value for the fully resolved key... String propVal = placeholderResolver.resolvePlaceholder(placeholder); //尝试获得最终占位符锁对应的值 if (propVal == null &amp;&amp; this.valueSeparator != null) { //没有找到placeholder对应的值，则可能出现存在默认值得情况 如#{key:defaultVal} int separatorIndex = placeholder.indexOf(this.valueSeparator); //查找字符串中的分隔符。 if (separatorIndex != -1) { //存在分隔符，则在尝试用真实key寻找对应值，如果不存在则使用默认值 String actualPlaceholder = placeholder.substring(0, separatorIndex); String defaultValue = placeholder.substring(separatorIndex + this.valueSeparator.length()); propVal = placeholderResolver.resolvePlaceholder(actualPlaceholder); if (propVal == null) { propVal = defaultValue; } } } if (propVal != null) { // Recursive invocation, parsing placeholders contained in the // previously resolved placeholder value. //当找到placeholder对应的值后，需要在对这个值中嵌套的placeholder进行处理,进行递归调用 propVal = parseStringValue(propVal, placeholderResolver, visitedPlaceholders); //替换placeholder result.replace(startIndex, endIndex + this.placeholderSuffix.length(), propVal); if (logger.isTraceEnabled()) { logger.trace(\"Resolved placeholder '\" + placeholder + \"'\"); } startIndex = result.indexOf(this.placeholderPrefix, startIndex + propVal.length()); } else if (this.ignoreUnresolvablePlaceholders) { // Proceed with unprocessed value. //忽略不能解析的占位符， startIndex = result.indexOf(this.placeholderPrefix, endIndex + this.placeholderSuffix.length()); } else { throw new IllegalArgumentException(\"Could not resolve placeholder '\" + placeholder + \"'\" + \" in value \\\"\" + value + \"\\\"\"); } visitedPlaceholders.remove(originalPlaceholder); } else { //没有结束符则将前缀作为placeholder的一部分 startIndex = -1; } } return result.toString();} 这是一个递归的过程，依次对字符串中的占位符进行解析，如果找到的资源中还存在占位符，那么会先对资源中的占位符进行解析，然后在替换原字符串中的占位符，以此类推，当出现循环引用时,如”placeholder=${placeholder} 则会抛出异常。","link":"/2018/12/10/spring/2_Environment/"},{"title":"（一）AbstractApplicationContext分析","text":"AbstractApplicationContext(下称AAC) 是Spring应用上下文的基类，通过调用此类的refresh()方法来初始化spring容器，它的依赖关系如图所示，大部分的接口方法在AAC中进行实现。 BeanFactoryBeanFactory是bean工厂的顶级接口，提供了一些访问bean容器的方法，他是bean容器最基本的视图，主要的子类有 HierarchicalBeanFactory 和 ListableBeanFactory 它提供的方法有： 12345678910111213141516171819202122232425262728293031//根据bean name, 或者bean type获得beanObject getBean(String name) throws BeansException; &lt;T&gt; T getBean(String name, Class&lt;T&gt; requiredType) throws BeansException;Object getBean(String name, Object... args) throws BeansException;&lt;T&gt; T getBean(Class&lt;T&gt; requiredType) throws BeansException;&lt;T&gt; T getBean(Class&lt;T&gt; requiredType, Object... args) throws BeansException;//获得ObjectProvider //ObjectFactory的变体 用于注入操作，以后深入&lt;T&gt; ObjectProvider&lt;T&gt; getBeanProvider(Class&lt;T&gt; requiredType);&lt;T&gt; ObjectProvider&lt;T&gt; getBeanProvider(ResolvableType requiredType);//是否存在beanboolean containsBean(String name);//是否为单例的beanboolean isSingleton(String name) throws NoSuchBeanDefinitionException;//是否为原型域的beanboolean isPrototype(String name) throws NoSuchBeanDefinitionException;//name对应的bean是否与typeToMatch类型一致boolean isTypeMatch(String name, ResolvableType typeToMatch) throws NoSuchBeanDefinitionException;boolean isTypeMatch(String name, Class&lt;?&gt; typeToMatch) throws NoSuchBeanDefinitionException;//获得bean的类型Class&lt;?&gt; getType(String name) throws NoSuchBeanDefinitionException;//获得bean的别名String[] getAliases(String name); 接下来 在看一下对他进行补充的两个主要的子类HierarchicalBeanFactory 和 ListableBeanFactory HierarchicalBeanFactoryHierarchicalBeanFactory 这个接口的意义是使BeanFactory可以获得父子关系，他提供了2个方法： 12345//获得当前BeanFactory的父工厂类BeanFactory getParentBeanFactory();//在当前工厂类中是否存在某个beanboolean containsLocalBean(String name); 通过这两个方法可以在具有父子关系的bean工厂中查找一个bean。 ListableBeanFactoryListableBeanFactory 使BeanFactory 获得了枚举所有bean实例的能力。如果当前工厂类是具有父子关系的，n那么这个接口中的方法只会考虑当前工厂类中的bean。它提供了这些方法： 1234567891011121314151617181920212223242526272829//确认当前bean工厂是否存在某个bean的定义boolean containsBeanDefinition(String beanName);//统计当前工厂中bean定义的数量，会忽略用其他方法的注册的bean。int getBeanDefinitionCount();//获得所有bean定义的名称String[] getBeanDefinitionNames();//通过类型寻找Bean定义String[] getBeanNamesForType(ResolvableType type);String[] getBeanNamesForType(@Nullable Class&lt;?&gt; type);String[] getBeanNamesForType(@Nullable Class&lt;?&gt; type, boolean includeNonSingletons, boolean allowEagerInit);//通过类型获得Bean&lt;T&gt; Map&lt;String, T&gt; getBeansOfType(@Nullable Class&lt;T&gt; type) throws BeansException;&lt;T&gt; Map&lt;String, T&gt; getBeansOfType(@Nullable Class&lt;T&gt; type, boolean includeNonSingletons, boolean allowEagerInit) throws BeansException;//获得所有存在某个注解的bean nameString[] getBeanNamesForAnnotation(Class&lt;? extends Annotation&gt; annotationType);//通过注解获得beanMap&lt;String, Object&gt; getBeansWithAnnotation(Class&lt;? extends Annotation&gt; annotationType) throws BeansException;//获得一个bean的注解@Nullable&lt;A extends Annotation&gt; A findAnnotationOnBean(String beanName, Class&lt;A&gt; annotationType) throws NoSuchBeanDefinitionException; 除了getBeanDefinitionCount和containsBeanDefinition，这个接口中的方法没有被当作频烦调用的方法设计，实现可以会慢。 ApplicationContextApplicationContext 是所有应用上下文锁都需要实现的接口，是spring容器中很重要的接口，他整合了EnvironmentCapable, ListableBeanFactory, HierarchicalBeanFactory, MessageSource, ApplicationEventPublisher, ResourcePatternResolver接口，以此提供了： 访问应用组件的工厂方法（ListableBeanFactory） 加载资源的能力（ResourceLoader） 发布注册事件消息的能力（ApplicationEventPublisher） 处理消息，支持国际化的能力（MessageSource） 获得父ApplicationContext的方法 在这里我们忽略ApplicationContext所继承的接口，主要分析ApplicationContext自己提供的方法： 1234567891011121314151617//获得当前上下文的唯一idString getId();//获得应用名称String getApplicationName();//获得上下文的名称String getDisplayName();//获得上下文进行首次加载的时间戳long getStartupDate();//获得父ApplicationContextApplicationContext getParent();//获取当前上下文的beanFactory(包装成AutowireCapableBeanFactory)AutowireCapableBeanFactory getAutowireCapableBeanFactory() throws IllegalStateException; 接下来继续分析ApplicationContext所继承的一些接口。 ResourceLoaderApplicationContext继承了ResourcePatternResolver接口，而ResourcePatternResolver是对ResourceLoader的一个拓展，它是一个加载资源的策略接口，ResourcePatternResolver本身提供了一个可以通过正则表达式加载资源的方法Resource[] getResources(String locationPattern) , 在ResourceLoader接口中又提供了这两个方法： 12345//通过一个确定路径获得资源Resource getResource(String location);//获得ClassLoader用于加载资源ClassLoader getClassLoader(); 在AbstractApplicationContext中，实际使用了一个叫做PathMatchingResourcePatternResolver独立的类作为资源加载器，在这个类中实现了Resource[] getResources(String locationPattern) 这个方法， 此外这个类又对ResourceLoader进行包装，并提供一个参数为ResourceLoader构造函数，通过策略模式来代理作为参数传入的ResourceLoader实现类。在实例化PathMatchingResourcePatternResolver类时，AAC又将本身作为参数，构造资源加载器。 1234567891011121314151617/** * Return the ResourcePatternResolver to use for resolving location patterns * into Resource instances. Default is a * {@link org.springframework.core.io.support.PathMatchingResourcePatternResolver}, * supporting Ant-style location patterns. * &lt;p&gt;Can be overridden in subclasses, for extended resolution strategies, * for example in a web environment. * &lt;p&gt;&lt;b&gt;Do not call this when needing to resolve a location pattern.&lt;/b&gt; * Call the context&apos;s {@code getResources} method instead, which * will delegate to the ResourcePatternResolver. * @return the ResourcePatternResolver for this context * @see #getResources * @see org.springframework.core.io.support.PathMatchingResourcePatternResolver */protected ResourcePatternResolver getResourcePatternResolver() { return new PathMatchingResourcePatternResolver(this);} 而AAC又是继承DefaultResourceLoader类的，所以ResourceLoader的声明的2个方法是在DefaultResourceLoader中实现的。在此先不展开，以后再进行分析。 ApplicationEventPublisher声明用于发布应用事件消息方法的接口, 它声明了两个方法： 1234567//一个默认的方法 用于发布框架事件default void publishEvent(ApplicationEvent event) { publishEvent((Object) event);}//发布事件，在AAC中实现void publishEvent(Object event); MessageSource一个用于国际化的接口，AAC默认使用一个DelegatingMessageSource来实现这个接口， 但DelegatingMessageSource只是一个空实现，如果需要实现国际化的操作需要使用者自定义messageSource来实现。spring为MessageSource提供了ResourceBundleMessageSource 和 ReloadableResourceBundleMessageSource 两个实现类。 EnvironmentCapable这个只声明了一个方法getEnvironment() 用于获得spring应用的运行环境。在AAC中，默认使用了StandardEnvironment类在作为这个接口的实现类。 ConfigurableApplicationContext该接口提供了一些配置和初始化应用上下文的方法： 1234567891011121314151617181920212223242526272829303132333435//设置当前上下文的唯一idvoid setId(String id);//设置父上下文void setParent(@Nullable ApplicationContext parent);//设置环境void setEnvironment(ConfigurableEnvironment environment);//获得环境ConfigurableEnvironment getEnvironment();//添加一个bean工厂后处理器void addBeanFactoryPostProcessor(BeanFactoryPostProcessor postProcessor);//添加一个应用监听器void addApplicationListener(ApplicationListener&lt;?&gt; listener);//添加一个协议解决器void addProtocolResolver(ProtocolResolver resolver);//刷新应用上下文， AAC也用这个方法来初始化上下文void refresh() throws BeansException, IllegalStateException;//注册一个jvm关闭钩子，可以被调用多次， 但最多只有一个hook会被注册void registerShutdownHook();//关闭应用上下文，释放所有资源，包括缓存的单例beanvoid close();//判断上下文是否可用boolean isActive();//获得一个可配置的bean工厂ConfigurableListableBeanFactory getBeanFactory() throws IllegalStateException; 应用上下文的初始化先看一下AAC的构造方法,他提供了2个构造方法： 12345678910//默认构造函数public AbstractApplicationContext() { this.resourcePatternResolver = getResourcePatternResolver();}//给定父上下文，进行构造public AbstractApplicationContext(@Nullable ApplicationContext parent) { this(); setParent(parent);} 在实例化AAC时，会调用getResourcePatternResolver()方法，这个方法实例化了一个PathMatchingResourcePatternResolver对象，作为AAC的资源加载器，当指定父上下文时，还会把父上下文的环境配置和当前上下文的环境进行合并。 1234567891011121314151617181920212223 public void setParent(@Nullable ApplicationContext parent) { this.parent = parent; if (parent != null) { Environment parentEnvironment = parent.getEnvironment(); if (parentEnvironment instanceof ConfigurableEnvironment) { getEnvironment().merge((ConfigurableEnvironment) parentEnvironment); } } }/** * Return the {@code Environment} for this application context in configurable * form, allowing for further customization. * &lt;p&gt;If none specified, a default environment will be initialized via * {@link #createEnvironment()}. */@Overridepublic ConfigurableEnvironment getEnvironment() { if (this.environment == null) { this.environment = createEnvironment(); //new StandardEnvironment() } return this.environment;} getEnvironment()是获得当前上下文的配置环境，AAC实例化配置环境的策略是懒加载的，只有第一次调用getEnvironment方法是才会为当前上下文指定一个配置环境。 实例化了一个应用上下文后，会调用refresh() 方法对上下文进行初始化。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Overridepublic void refresh() throws BeansException, IllegalStateException { synchronized (this.startupShutdownMonitor) { // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); //重建一个DefaultListableBeanFactory // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); //构造BeanFactory try { // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); } catch (BeansException ex) { if (logger.isWarnEnabled()) { logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); } // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; } finally { // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); } }} prepareRefresh() 方法会做一些刷新之前的操作： 重置上下文的启动时间为当前时间 重置上下文的运行状态 验证环境中的properties 清空上下文事件列表 做完了上述操作后，接着会调用obtainFreshBeanFactory()方法，这个方法需要子类进行重写，他的主要功能是为应用上下文新建一个Bean工厂, 加载BeanDefinition ，此处先不展开。 接着调用的是prepareBeanFactory()方法来对BeanFactory做一些配置。此时BeanFactory已经准备完毕了，单做的都是标准配置，AAC提供了一个可以让子类修改BeanFactory配置的方法，子类通过重写这个方法可以修改BeanFactory。 接下来，符合要求的BeanFactory才算真正的配置完成，这个时候就会向所有实现BeanFactoryPostProcessor 的Bean发布消息，通过调用invokeBeanFactoryPostProcessors()方法来调用这些bean实现的postProcessBeanFactory()方法。 然后是registerBeanPostProcessors()方法，用来注册bean处理器。 接着是初始化MessageSource,初始化应用事件分发器，初测监听类。 随后调用finishBeanFactoryInitialization()完成Bean的初始化，实例化所有非懒加载的单例bean. 最后在finishRefresh()方法中完成相关事件的发布。","link":"/2018/11/27/spring/1_AbstractApplicationContext/"},{"title":"Java内存区域","text":"对于从事C、C++的开发人员来说，在内存管理方面他们对于每一个对象都拥有所有权，需要负责每一个对象的创建与销毁。对于从事Java的开发人员来说，由于有垃圾回收机制的存在，可以不用对对象的内存管理负责，但一旦出现内存泄漏，如果不了解虚拟机的内存机制，对于开发人员来说查找错误是非常困难的。 运行时数据区域 在Jvm规范中，规定了上图所示的几个数据区域，有些是所有线程都共享的，有些则是线程隔离的。 程序计数器​ 程序计数器可以看做当前所执行字节码指令的行号指示器。由于，JVM需要在切换线程之后，恢复至正确的执行位置，所以每一个线程都需要一个程序计数器来记录当前执行位置，且各个线程直接互不影响。 ​ 程序计数器只存储当前执行字节码指令的地址，所以这是一个固定的大小，所以程序计数器也是JVM规范中唯一个没有 OutOfMemoryError 的区域。当JVM所执行的是Native方式时，这个计数器为空。 Java栈​ Java栈也是一个线程私有的内存区域，他描述了Java方法执行的内存模型，在每个方法执行的同时，会新建一个栈帧，用于存储局部变量表，方法出口等信息。当一个方法执行完毕，就会有一个栈帧出栈。 ​ 局部变量表存放着编译期可知的所有基本类型的变量、对象引用和返回值类型。其中，64位长度的long和double需要占用2个局部变量空间，其余类型只需要占用一个。局部变量表所需要的空间，在编译期就已经完成分配，执行这个方法需要在帧中分配多少空间是完全确定的，在运行期间不会改变这个空间的大小。 Java栈有2种异常类型: StackOverFlowError: 请求的栈深度大于虚拟机所允许的栈深度 OutOfMemoryError: 某些虚拟机栈支持动态扩展，当虚拟机无法申请到足够的内存空间时，就会抛出这个异常。 本地方法栈​ 与Java栈一样，都是描述一个方法执行的内存模型，只是本地方法栈描述的是Native方法的执行。与Java栈一样都会抛出StackOverFlowError和OutOfMemoryError异常。 Java堆​ Java堆是一个被所有线程都共享的区域，几乎所有的对象都需要在这个区域上被分配，所以Java堆也是垃圾收集器管理的主要区域，Java堆也因此被称为 GC堆，由于垃圾收集器的不同，Java堆还可以本细分为很多种情况，这会在以后进行讨论。 ​ Java堆可以处于物理上不连续的内存空间中，只需要逻辑上连续即可。当Java堆无法申请到足够大的空间来分配对象时，会抛出OutOfMemoryError异常。 方法区方法区也是一个线程共享的区域，用于存储已经被JVM加载的类信息，常量，静态变量，即时编译器编译后的代码等数据。在HotSpot虚拟机中，这个区域也别称作`永久代` ，因为HotSpot团队将GC分代收集拓展至了方法区，或者说，用永久代来实现了方法区，这样HotSpot的垃圾收集器就可以像管理Java堆一样管理这块内存了。 ​ 方法区和Java堆一眼，不需要再物理上连续的内存区域，除了可以选择固定大小或者可拓展外，还可以选择是否实现垃圾收集。这块内存可能会抛出OutOfMemoryError异常。 运行时常量池​ 这块区域是方法区的一部分，Class文件中除了有类的版本、字段、方法、接口等描述信息，还有一项常量池，用于存放编译期可知的各种符号引用，这部分内容将在类加载之后放入运行时常量池中存放。 ​ 运行时常量池还具有动态性，在运行期间，也可能产生新的常量，如String 的 intern（） 方法。 Java对象对象的创建​ Java对象的创建一般步骤是这样的： ​ （1）当JVM遇到一条new指令时，先会去检查常量池中，是否存在这个类的符号引用，并且检测这个类是否已经被加载、解析和初始化，如果没有将先进行相应类加载过程。 ​ （2）当类加载过程完成之后，需要在Java堆中分配相应大小的内存空间来容纳这个新创建的对象。由于，开发人员可以选择在Java堆使用什么垃圾收集器，而不同的垃圾收集器因为回收算法的不同，回收后的Java堆中的内存可能不是规整的，所以根据内存的规整与否，会采取不同的方法来分配内存。对于规整的内存，可以采用指针碰撞的方法 ，这个方法需要维护一个指针作为分界点的指示器，这个指针的一遍是已经被分配的内存，另一边是未被分配的内存，当需要分配一块内存时，只需要将这个指针向未被分配的那一边移动相应大小。对于内存不规整的情况，可以使用空闲列表的方法，这个方法需要额外维护一个足够大的列表用来记录Java对中哪些内存块是未被使用的，当分配内存时，只需要在这个列表中找到一块足够大的内存空间就可以了。除了如何划分空间之外，内存分配是一个非常频繁的操作，如何保证在多线程环境下保证线程安全也是一个需要考虑的问题，一般有2中解决方法：第一种是CAS+重试的方法，当JVM在进行分配操作时，会用原子的方式去尝试分配，如果分配失败，将会进行重试；另一种是为每个线程分配一个TLAB(Thread Local Allocation Buffer, 本地线程分配缓存)，一个线程会在属于自己线程的TLAB中分配空间。 ​ （3）内存分配完成之后，虚拟机需要将分配到的内存空间都初始化为0值。 ​ （4）接下来，需要对对象进行必要的设置，比如这个对象是哪个类的实例，如何才能找到这个类的元数据信息，对象的哈希，对象的分代年龄信息等，这些都存储在对象头中。 ​ （5）在完成了以上操作后，在JVM角度，一个对象已经产生了，但是一般来说，一个对象还需要按照开发人员的意愿进行初始化，所以JVM执行完new指令是接着会执行方法，对对象进行初始化操作。 对象的内存布局​ 在HotSpot虚拟机中，对象的内存布局配分为3块：对象头、实例数据、对齐填充。 对象头​ HotSpot的对象头包括2部分，一部分是记录对象的运行时数据，如哈希码，GC分代年龄，锁状态标志，线程持有的锁，偏向线程ID，偏向时间戳等，这部分数据长度在32bit和64bit的JVM中分别为32bit和64bit；另一部分是类型指针，即对象执行他的类元数据的指针，通过这个指针，可以知道这个对象是哪个类的实例，对于数组对象，这里还有有一个表示数组大小的标志。 实例数据​ 实例数据部分是对象真正存储有效数据的地方，无论是在父类中继承的还是在子类中定义的，都会在这里被记录。这部分的存储顺序会受到JVM的分配策略和在源码中定义的顺序的影响。 对齐填充​ 一个对象实例在内存中所占空间的大小，必须是8字节的整数倍，所以，需要这块空间将一个对象填充。 对象的定位​ 创建对象是为了使用对象，在Java栈的局部变量表中只存储了指向这个对象的引用，却没有规定如何通过这个引用去找到对象，接下来，我会介绍一下2中主流的定位对象的方法：通过使用句柄和直接访问。 使用句柄​ 如果使用句柄的话需要在Java堆中额外划分出一块句柄池，用于存储对象在Java堆中的具体位置信息和对象实例数据，在局部变量表中的引用实际指向的是局部池中对于句柄的位置。 直接访问​ 直接访问，那么reference中存储的就是对象在Java堆中的地址，这种方式需要考虑如何放置访问类型数据的相关信息。 这2种方法各有利弊，对于通过句柄访问，会浪费一次指针定位的开销，但当对象被移动时（如垃圾回收时），只需要修改对象在句柄池中的指针，而不需要修改Java栈中的指针。对于第二种，最大的好处就是速度更快。HotSpot虚拟机采用了第二种方法。","link":"/2018/04/14/jvm/JavaMemory/"}],"tags":[{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"RPC","slug":"RPC","link":"/tags/RPC/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"}],"categories":[{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"JVM","slug":"JVM","link":"/categories/JVM/"},{"name":"源码阅读","slug":"Java/源码阅读","link":"/categories/Java/源码阅读/"},{"name":"RPC","slug":"Java/RPC","link":"/categories/Java/RPC/"},{"name":"Spring源码","slug":"Java/Spring源码","link":"/categories/Java/Spring源码/"},{"name":"内存管理","slug":"JVM/内存管理","link":"/categories/JVM/内存管理/"}]}